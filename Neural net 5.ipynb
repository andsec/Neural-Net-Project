{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Test\n",
    "using Profile\n",
    "using Traceur\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "#using CuArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CUDAdrv → `C:\\Users\\Andre\\.julia\\packages\\CUDAdrv\\lu32K\\deps\\build.log`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Error building `CUDAdrv`: \n",
      "│ Initializing CUDA driver failed: unknown error (code 999)..\n",
      "└ @ Pkg.Operations C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.0\\Pkg\\src\\Operations.jl:1097\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.build(\"CUDAdrv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct NeuralNetwork\n",
    "    weights::Array\n",
    "    biases::Array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createNetwork (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createNetwork(layers::Tuple)::NeuralNetwork\n",
    "    network = NeuralNetwork([],[])\n",
    "    for i in 1:length(layers)-1\n",
    "        weightMatrix = randn(layers[i+1],layers[i])\n",
    "        push!(network.weights,weightMatrix)\n",
    "        biasVector = randn(layers[i+1])\n",
    "        push!(network.biases,biasVector)\n",
    "    end\n",
    "    return network\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ffInput (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function takes a network and feeds an input vector through\n",
    "# to return lists of activations and z = (W*a + b)\n",
    "function feedForward(network::NeuralNetwork, x::Array)\n",
    "    activations = [x]\n",
    "    zList = []\n",
    "\n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        z = W*x + b\n",
    "        push!(zList, z)\n",
    "        x = sigmoid.(z)\n",
    "        push!(activations, x)\n",
    "    end\n",
    "\n",
    "    return activations, zList\n",
    "end\n",
    "\n",
    "# Function passes single input through network and returns answer\n",
    "function ffInput(network::NeuralNetwork, x::Array)::Array\n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        x = sigmoid.(W*x + b)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelToVector (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function takes an image label number and creates a 10x1 vector \n",
    "# with a 1 in the position of the number\n",
    " \n",
    "function labelToVector(label::Int64)::Array\n",
    "    labelVector = zeros(10)\n",
    "    labelVector[label + 1] = 1\n",
    "    return labelVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidPrime (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Number) = 1/(1 + exp(-x))\n",
    "sigmoidPrime(x::Number) = sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backPropagation (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function takes a network, input, and label to compute gradients\n",
    "# for the network's weights and biases and returns these gradients \n",
    "# in lists\n",
    "function backPropagation(network::NeuralNetwork, input::Array, label::Int64)\n",
    "    label = labelToVector(label)\n",
    "    nabla_w = [] # Array to hold weight gradients\n",
    "    nabla_b = [] # Array to hold bias gradients\n",
    "    aList, zList = feedForward(network, input)\n",
    "    delta = (aList[end] - label) .* sigmoidPrime.(zList[end])\n",
    "    pushfirst!(nabla_b, delta)\n",
    "    wDelta = delta * aList[end - 1]'\n",
    "    pushfirst!(nabla_w, wDelta)\n",
    "\n",
    "    for i in 0:length(network.weights)-2\n",
    "        delta = (net.weights[end - i]' * delta) .* sigmoidPrime.(zList[end - i - 1])\n",
    "        pushfirst!(nabla_b, delta)\n",
    "        wDelta = delta * aList[end - i - 2]'\n",
    "        pushfirst!(nabla_w, wDelta)\n",
    "    end\n",
    "    \n",
    "    return nabla_b, nabla_w\n",
    "end\n",
    "\n",
    "#Function does the same as above with cross entropy instead of quadratic cost\n",
    "function backPropagation2(network::NeuralNetwork, input::Array, label::Int64)\n",
    "    label = labelToVector(label)\n",
    "    nabla_w = [] # Array to hold weight gradients\n",
    "    nabla_b = [] # Array to hold bias gradients\n",
    "    aList, zList = feedForward(network, input)\n",
    "    delta = crossEntropy.(aList[end], label) .* (aList[end]-)\n",
    "    pushfirst!(nabla_b, delta)\n",
    "    wDelta = delta * aList[end - 1]'\n",
    "    pushfirst!(nabla_w, wDelta)\n",
    "\n",
    "    for i in 0:length(network.weights)-2\n",
    "        delta = (net.weights[end - i]' * delta) .* sigmoidPrime.(zList[end - i - 1])\n",
    "        pushfirst!(nabla_b, delta)\n",
    "        wDelta = delta * aList[end - i - 2]'\n",
    "        pushfirst!(nabla_w, wDelta)\n",
    "    end\n",
    "    \n",
    "    return nabla_b, nabla_w\n",
    "end\n",
    "\n",
    "#Function computes cross entropy and returns 0 if calculation results in nan or inf\n",
    "function crossEntropy(a::Number, y::Number)\n",
    "    cost = -y*log(a) - (1-y)*log(1-a)\n",
    "    if isinf(cost) || isnan(cost)\n",
    "        return 0.0\n",
    "    else\n",
    "        return cost\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateMiniBatch! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateMiniBatch!(network::NeuralNetwork, miniBatch::Array, eta::Number)\n",
    "    m = length(miniBatch)\n",
    "    nablaB = [zero(b) for b in network.biases]\n",
    "    nablaW = [zero(w) for w in network.weights]\n",
    "    for (input, label) in miniBatch\n",
    "        deltaB, deltaW = backPropagation(network, input, label)\n",
    "        nablaB = [nb+dnb for (nb, dnb) in zip(nablaB, deltaB)]\n",
    "        nablaW = [nw+dnw for (nw, dnw) in zip(nablaW, deltaW)]\n",
    "    end\n",
    "    network.weights = [W-(eta/m)*nW for (W, nW) in zip(network.weights,nablaW)]\n",
    "    network.biases = [b-(eta/m)*nb for (b, nb) in zip(network.biases,nablaB)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function returns the number of test inputs for which the network\n",
    "# outputs the correct result\n",
    "\n",
    "function evaluate(network::NeuralNetwork, testData::Array)::Number\n",
    "    testResults = [(argmax(ffInput(network,input))-1,label) for (input,label) in testData]\n",
    "    return sum(Int64(x==y) for (x,y) in testResults)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD! (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function performs stochastic gradient descent\n",
    "function SGD!(network::NeuralNetwork, trainingData::Array, testData::Array, epochs::Number, miniBatchSize::Number, eta::Number)\n",
    "    n = length(trainingData)\n",
    "    nTest = length(testData)\n",
    "    for i in 1:epochs\n",
    "        shuffle!(trainingData)\n",
    "        miniBatches = [trainingData[k:k+miniBatchSize-1] for k in 1:miniBatchSize:n]\n",
    "        for mb in miniBatches\n",
    "            updateMiniBatch!(network,mb,eta)\n",
    "        end\n",
    "        numCorrect = evaluate(network,testData)\n",
    "        println(\"Epoch $i: $numCorrect/$nTest\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnistConverter (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function converts mnist data into workable format\n",
    "function mnistConverter(inputs,labels)\n",
    "    vectors = [convert(Array{Float64,1},vec(inputs[:, :, i])) for i in 1:size(inputs,3)]\n",
    "    return collect(zip(vectors,convert(Array{Int64,1},labels)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "train_x, train_y = MNIST.traindata(1:2)\n",
    "test_x,  test_y  = MNIST.testdata(1:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Tuple{Array{Float64,1},Int64},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 7)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = mnistConverter(train_x,train_y)\n",
    "testData = mnistConverter(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(Any[[1.44444 0.768688 … -0.512279 -0.603474; -1.2145 1.4125 … -0.854687 1.2306; … ; 1.87387 -0.436123 … 0.938041 -0.246723; -1.78963 -0.773634 … 1.03086 -0.972938], [1.26145 -0.580334 … 0.947361 1.01339; 0.502065 -0.310575 … -0.982824 -0.191458; … ; -1.08009 0.00504403 … -1.05233 -0.0585738; 0.400818 0.530568 … 0.765188 -0.838112]], Any[[1.51529, 0.049334, 0.967461, 0.457381, 0.55865, 0.486873, -0.419933, 0.640075, 1.72451, -1.37599  …  0.514081, -0.873241, 1.0894, 0.214044, 1.21756, 1.02496, 0.305114, 0.240682, -0.339459, -0.656797], [0.0387723, -0.340905, 0.202012, 0.261148, 0.45623, 0.658789, 0.0618018, -1.42886, 0.418539, -1.06461]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = createNetwork((784,30,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD!(net,trainingData,testData,1,1,3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isnan(log(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
