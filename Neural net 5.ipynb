{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct NeuralNetwork\n",
    "    weights::Array\n",
    "    biases::Array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createNetwork (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createNetwork(layers::Tuple)::NeuralNetwork\n",
    "    network = NeuralNetwork([],[])\n",
    "    for i in 1:length(layers)-1\n",
    "        weightMatrix = randn(layers[i+1],layers[i])\n",
    "        push!(network.weights,weightMatrix)\n",
    "        biasVector = randn(layers[i+1])\n",
    "        push!(network.biases,biasVector)\n",
    "    end\n",
    "    return network\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ffInput (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function takes a network and feeds an input vector through\n",
    "# to return lists of activations and z = (W*a + b)\n",
    "function feedForward(network::NeuralNetwork, input::Array)\n",
    "    \n",
    "    a = input\n",
    "    activations = [a]\n",
    "    zList = []\n",
    "    \n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        z = W*a + b\n",
    "        push!(zList, z)\n",
    "        a = sigmoid.(z)\n",
    "        push!(activations, a)\n",
    "    end\n",
    "    \n",
    "    return activations, zList\n",
    "end\n",
    "\n",
    "# Function passes single input through network and returns answer\n",
    "function ffInput(network::NeuralNetwork, x::Array)::Array\n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        x = sigmoid.(W*x + b)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelToVector (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function takes an image label number and creates a 10x1 vector \n",
    "# with a 1 in the position of the number\n",
    " \n",
    "function labelToVector(label::Int64)::Array\n",
    "    labelVector = zeros(10)\n",
    "    labelVector[label + 1] = 1\n",
    "    return labelVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidPrime (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Number) = 1/(1 + exp(-x))\n",
    "sigmoidPrime(x::Number) = sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backPropagation (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "# Function takes a network, input, and label to compute gradients\n",
    "# for the network's weights and biases and returns these gradients \n",
    "# in lists\n",
    "\n",
    "function backPropagation(network::NeuralNetwork, input::Array, label::Int64)\n",
    "    label = labelToVector(label)\n",
    "    nabla_w = [] # Array to hold weight gradients\n",
    "    nabla_b = [] # Array to hold bias gradients\n",
    "    aList, zList = feedForward(network, input)\n",
    "    delta = (aList[end] - label) .* sigmoidPrime.(zList[end])\n",
    "    pushfirst!(nabla_b, delta)\n",
    "    wDelta = delta * aList[end - 1]'\n",
    "    pushfirst!(nabla_w, wDelta)\n",
    "    \n",
    "    for i in 0:length(network.weights)-2\n",
    "        delta = (net.weights[end - i]' * delta) .* sigmoidPrime.(zList[end - i - 1])\n",
    "        pushfirst!(nabla_b, delta)\n",
    "        wDelta = delta * aList[end - i - 2]'\n",
    "        pushfirst!(nabla_w, wDelta)\n",
    "    end\n",
    "    \n",
    "    return nabla_b, nabla_w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateMiniBatch! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateMiniBatch!(network::NeuralNetwork, miniBatch::Array, eta::Number)\n",
    "    m = length(miniBatch)\n",
    "    nablaB = [zero(b) for b in network.biases]\n",
    "    nablaW = [zero(w) for w in network.weights]\n",
    "    for (input, label) in miniBatch\n",
    "        deltaB, deltaW = backPropagation(network, input, label)\n",
    "        nablaB = [nb+dnb for (nb, dnb) in zip(nablaB, deltaB)]\n",
    "        nablaW = [nw+dnw for (nw, dnw) in zip(nablaW, deltaW)]\n",
    "    end\n",
    "    network.weights = [W-(eta/m)*nW for (W, nW) in zip(network.weights,nablaW)]\n",
    "    network.biases = [b-(eta/m)*nb for (b, nb) in zip(network.biases,nablaB)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function returns the number of test inputs for which the network\n",
    "# outputs the correct result\n",
    "\n",
    "function evaluate(network::NeuralNetwork, testData::Array)::Number\n",
    "    testResults = [(argmax(ffInput(network,input))-1,label) for (input,label) in testData]\n",
    "    return sum(Int64(x==y) for (x,y) in testResults)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "# Function performs stochastic gradient descent\n",
    "function SGD!(network::NeuralNetwork, trainingData::Array, testData::Array, epochs::Number, miniBatchSize::Number, eta::Number)\n",
    "    n = length(trainingData)\n",
    "    nTest = length(testData)\n",
    "    for i in 1:epochs\n",
    "        shuffle!(trainingData)\n",
    "        miniBatches = [trainingData[k:k+miniBatchSize-1] for k in 1:miniBatchSize:n]\n",
    "        for mb in miniBatches\n",
    "            updateMiniBatch!(network,mb,eta)\n",
    "        end\n",
    "        numCorrect = evaluate(network,testData)\n",
    "        println(\"Epoch $i: $numCorrect/$nTest\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnistConverter (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function converts mnist data into workable format\n",
    "function mnistConverter(inputs,labels)\n",
    "    vectors = [convert(Array{Float64,1},vec(inputs[:, :, i])) for i in 1:size(inputs,3)]\n",
    "    return collect(zip(vectors,convert(Array{Int64,1},labels)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2, 1, 0, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "train_x, train_y = MNIST.traindata(1:5)\n",
    "test_x,  test_y  = MNIST.testdata(1:5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Tuple{Array{Float64,1},Int64},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 7)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = mnistConverter(train_x,train_y)\n",
    "testData = mnistConverter(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(Any[[0.875315 -0.171041 … 1.53242 0.217799; -0.971041 0.644642 … 0.208482 -0.537842; … ; -1.89493 -0.0719117 … 2.00529 1.6683; -1.66609 -0.646334 … 1.33292 -0.509891], [-0.529806 0.168624 … -1.23484 -0.745847; -0.191047 -1.09056 … -1.11786 -1.01957; … ; -0.179932 -0.883614 … 1.02452 0.183943; 0.339666 -1.11269 … 0.0100294 -0.220737]], Any[[-0.676031, 0.0818956, 0.374857, 1.11205, -1.46125, -0.109917, 0.919051, 0.884505, -0.799572, -0.180999  …  1.66154, 0.323723, -0.887067, -0.5225, -0.152034, -0.431007, 0.603144, -0.490588, -1.97647, -0.479901], [0.69402, -1.46159, -0.0201361, -0.982483, -1.69132, 0.368173, 1.13283, 0.790487, 0.795625, -0.186452]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = createNetwork((784,30,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1459/10000\n"
     ]
    }
   ],
   "source": [
    "SGD!(net,trainingData,testData,1,1000,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
