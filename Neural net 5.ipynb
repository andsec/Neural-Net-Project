{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Test\n",
    "using Profile\n",
    "using Traceur\n",
    "#using CuArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CUDAdrv → `C:\\Users\\Andre\\.julia\\packages\\CUDAdrv\\lu32K\\deps\\build.log`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Error building `CUDAdrv`: \n",
      "│ Initializing CUDA driver failed: unknown error (code 999)..\n",
      "└ @ Pkg.Operations C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.0\\Pkg\\src\\Operations.jl:1097\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.build(\"CUDAdrv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct NeuralNetwork\n",
    "    weights::Array\n",
    "    biases::Array\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createNetwork (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createNetwork(layers::Tuple)::NeuralNetwork\n",
    "    network = NeuralNetwork([],[])\n",
    "    for i in 1:length(layers)-1\n",
    "        weightMatrix = randn(layers[i+1],layers[i])\n",
    "        push!(network.weights,weightMatrix)\n",
    "        biasVector = randn(layers[i+1])\n",
    "        push!(network.biases,biasVector)\n",
    "    end\n",
    "    return network\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ffInput (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function takes a network and feeds an input vector through\n",
    "# to return lists of activations and z = (W*a + b)\n",
    "function feedForward(network::NeuralNetwork, x::Array)\n",
    "    activations = [x]\n",
    "    zList = []\n",
    "\n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        z = W*x + b\n",
    "        push!(zList, z)\n",
    "        x = sigmoid.(z)\n",
    "        push!(activations, x)\n",
    "    end\n",
    "\n",
    "    return activations, zList\n",
    "end\n",
    "\n",
    "# Function passes single input through network and returns answer\n",
    "function ffInput(network::NeuralNetwork, x::Array)::Array\n",
    "    for (W,b) in zip(network.weights, network.biases)\n",
    "        x = sigmoid.(W*x + b)\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelToVector (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function takes an image label number and creates a 10x1 vector \n",
    "# with a 1 in the position of the number\n",
    " \n",
    "function labelToVector(label::Int64)::Array\n",
    "    labelVector = zeros(10)\n",
    "    labelVector[label + 1] = 1\n",
    "    return labelVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidPrime (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Number) = 1/(1 + exp(-x))\n",
    "sigmoidPrime(x::Number) = sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backPropagation (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "# Function takes a network, input, and label to compute gradients\n",
    "# for the network's weights and biases and returns these gradients \n",
    "# in lists\n",
    "\n",
    "function backPropagation(network::NeuralNetwork, input::Array, label::Int64)\n",
    "    label = labelToVector(label)\n",
    "    nabla_w = [] # Array to hold weight gradients\n",
    "    nabla_b = [] # Array to hold bias gradients\n",
    "    aList, zList = feedForward(network, input)\n",
    "    delta = (aList[end] - label) .* sigmoidPrime.(zList[end])\n",
    "    pushfirst!(nabla_b, delta)\n",
    "    wDelta = delta * aList[end - 1]'\n",
    "    pushfirst!(nabla_w, wDelta)\n",
    "\n",
    "    for i in 0:length(network.weights)-2\n",
    "        delta = (net.weights[end - i]' * delta) .* sigmoidPrime.(zList[end - i - 1])\n",
    "        pushfirst!(nabla_b, delta)\n",
    "        wDelta = delta * aList[end - i - 2]'\n",
    "        pushfirst!(nabla_w, wDelta)\n",
    "    end\n",
    "    \n",
    "    return nabla_b, nabla_w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateMiniBatch! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateMiniBatch!(network::NeuralNetwork, miniBatch::Array, eta::Number)\n",
    "    m = length(miniBatch)\n",
    "    nablaB = [zero(b) for b in network.biases]\n",
    "    nablaW = [zero(w) for w in network.weights]\n",
    "    for (input, label) in miniBatch\n",
    "        deltaB, deltaW = backPropagation(network, input, label)\n",
    "        nablaB = [nb+dnb for (nb, dnb) in zip(nablaB, deltaB)]\n",
    "        nablaW = [nw+dnw for (nw, dnw) in zip(nablaW, deltaW)]\n",
    "    end\n",
    "    network.weights = [W-(eta/m)*nW for (W, nW) in zip(network.weights,nablaW)]\n",
    "    network.biases = [b-(eta/m)*nb for (b, nb) in zip(network.biases,nablaB)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function returns the number of test inputs for which the network\n",
    "# outputs the correct result\n",
    "\n",
    "function evaluate(network::NeuralNetwork, testData::Array)::Number\n",
    "    testResults = [(argmax(ffInput(network,input))-1,label) for (input,label) in testData]\n",
    "    return sum(Int64(x==y) for (x,y) in testResults)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "# Function performs stochastic gradient descent\n",
    "function SGD!(network::NeuralNetwork, trainingData::Array, testData::Array, epochs::Number, miniBatchSize::Number, eta::Number)\n",
    "    n = length(trainingData)\n",
    "    nTest = length(testData)\n",
    "    for i in 1:epochs\n",
    "        shuffle!(trainingData)\n",
    "        miniBatches = [trainingData[k:k+miniBatchSize-1] for k in 1:miniBatchSize:n]\n",
    "        for mb in miniBatches\n",
    "            updateMiniBatch!(network,mb,eta)\n",
    "        end\n",
    "        numCorrect = evaluate(network,testData)\n",
    "        println(\"Epoch $i: $numCorrect/$nTest\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnistConverter (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function converts mnist data into workable format\n",
    "function mnistConverter(inputs,labels)\n",
    "    vectors = [convert(Array{Float64,1},vec(inputs[:, :, i])) for i in 1:size(inputs,3)]\n",
    "    return collect(zip(vectors,convert(Array{Int64,1},labels)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "FixedPointNumbers.Normed{UInt8,8}[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,  test_y  = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Tuple{Array{Float64,1},Int64},1}:\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 7)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 4)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 4)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 9)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 5)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 9)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 6)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 9)\n",
       " ⋮                                                                                                           \n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 5)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 6)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 7)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 8)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 9)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 1)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 2)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 3)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 4)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 5)\n",
       " ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = mnistConverter(train_x,train_y)\n",
    "testData = mnistConverter(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(Any[[-0.61827 -0.00645018 … 0.506456 0.311127; 1.06463 -2.10176 … -0.471339 1.99114; … ; 0.502761 -1.24851 … 1.2198 -0.283598; -0.872706 0.446547 … -0.412292 -1.0104], [0.416856 2.07815 … -0.352516 1.01687; -0.102343 0.981661 … -0.389077 1.19999; … ; -0.37257 0.722652 … 0.652613 0.398809; 0.320502 0.396477 … 0.0241236 -0.254712]], Any[[-0.901046, 0.171992, -0.53581, -0.301479, 0.0447115, -0.519136, -1.67725, 1.244, -0.947674, 1.03363  …  -0.690993, -0.178006, 0.79196, -2.81532, -0.309629, 2.76725, -0.302805, 1.04048, -2.01615, 1.55649], [-0.905893, -0.35701, 1.42227, -0.0506743, -0.296568, -0.165196, 1.31754, 1.60571, 0.988851, -0.668661]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = createNetwork((784,30,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 9351/10000\n",
      "Epoch 1: 9386/10000\n",
      "Epoch 1: 9401/10000\n",
      "Epoch 1: 9437/10000\n",
      "  38.280 s (4292188 allocations: 24.82 GiB)\n"
     ]
    }
   ],
   "source": [
    "@btime SGD!(net,trainingData,testData,1,10,3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
